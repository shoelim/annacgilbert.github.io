---
title: "(1) Machine learning by open dynamical systems, for open dynamical systems"
collection: portfolio
---
Recurrent neural networks (RNNs) are a class of powerful open system models in machine learning that have also enjoyed synergies with disciplines such as neuroscience, signal processing, optimization, control theory and network science. The explosion of real-time data (physical or not) and the promising potential of using dynamical systems (physically realizable or not) to learn the data are opening up a wide range of foundational and practical problems. However, the dearth of rigorous analysis limits the usefulness of RNNs in addressing scientific questions. Therefore, a deep understanding of the working mechanism of RNNs and related models is pivotal to shed light on the properties of large and adaptive architectures, and to facilitate systematic design of the next generation of networks.

On one hand, we are working on various mathematical aspects of RNNs and related models in the context of deep learning. On the other hand, we are always looking to apply the models and theory to study complex dynamical systems arising in science and engineering. The theory and applications go hand in hand for us. For theoretical analysis, we use tools and techniques from  stochastic analysis, rough paths theory, statistical learning, among others. For applications, we are primarily inspired by ideas and insights from statistical mechanics and nonlinear science. We are also interested to explore brain and quantum models of RNNs and related models. <i>Check out the relevant research outputs [<font color = "blue">here</font>](https://shoelim.github.io/publications/).</i>
<br>
<br>
